{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gabrielle Martinez   \n",
    "Professor Kaltenberg   \n",
    "ECO590 Data Analysis with Python and R   \n",
    "6 October 2020   \n",
    "\n",
    "## Assignment 2: Project Proposal\n",
    "\n",
    "\n",
    "    1. Identify the website/API that you will be web-scraping data from. You can also suggest a variety of websites via web crawling (for example, if you want to crawl websites of selected non-profit organizations and collect information about the board members - this is doable.)\n",
    "\n",
    "I'll be webscrapping information from the [Mergent Archive](https://www-mergentarchives-com.rlib.pace.edu/search.php) which holds Moodyâ€™s Manual collection from 1909 to 2018. It has a search feature but it presents most of it's data as a pdf. The file types are inconsistant with each year, some saving as tiffs, other as php files. I'll have to account for this, in order to extract the tables I want using python. \n",
    "\n",
    "    2. Define at least 3 variables that you will be collecting. You can only web-scrape one variable so long as you are combining this data with other data sources. You must list those other data source variables.\n",
    "\n",
    "I want to scrap firm level data variables, so R&D if I can find it, the number of employees the company has, and maybe bond rating/average stock price for the year. \n",
    "\n",
    "    3. If it is an open access API, get an authorization key (if neccessary), if it is not needed, also note that. Provide evidence of this with screen shot that you obtained said key or a link (and a summary in your proposal) of the documentation that says it's freely accessible.\n",
    "    \n",
    "There is no API. I'll be downloading the pdf output (either manually or automating it if I can) and running the pdf files through python. There are a number of python libraries to extract tables from pdfs. \n",
    "\n",
    "    4. If it is not an open access API, ensure that you meet the terms and conditions (there is wiggle room here - but, if you are trying to crack a google related non-open access API, that's unreasonable and not possible in this class. However, if it is a Google/Amazon/InsertBigTechComp with open access API - that is do-able!). Most websites have terms and conditions, include a link to this information and briefly (a few sentences) describe what you can or can't get access to.\n",
    "    \n",
    "The [terms of use](https://www-mergentarchives-com.rlib.pace.edu/static.php?q=sla) don't seem to deny me any access, only that I not copy or share the information I gather (which I'm guessing means don't publish the files I download), and that they hold no responsiblity for what I download (if I get a virus from downloading one of their files, they're not responsible). They also make no claims as to the accuracy of the information, giving the information on an \"as is\" basis. The files are a primary source of the times so I'm not worried about the accuracy of the information I'm accessing.  \n",
    "\n",
    "    5. Identify your research question - what are you going to analyze? Remember that after getting the data, you will make meaningful graphs and run regressions with it.\n",
    "\n",
    "For this project, I want to gather and analyze data that will help me in my capstone project that I am currently taking alongside this course. The purpose of my capstone project is to study the effects of regulation on green innovation using the 1973 oil crisis and the subsiquent fuel standard regulations as a case study. \n",
    "\n",
    "\n",
    "    6. Give me a bit of background and motivation. Why are you scraping this data? Why should you research/study this question?\n",
    "\n",
    "I think this topic is important to study because innovation is an important part of keeping the US competative on the world stage and regulation is important for our health and the health of out planet. If policy makers can support both, without sacrificing one for the either, then well-designed regulation can become an important tool for promoting both innovation and protection for our enviroment. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
